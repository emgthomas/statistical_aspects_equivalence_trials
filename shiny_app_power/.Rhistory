#
# # Compute power for above sample size assuming PPV < 1
# ppv_min <-  0.5
# tfr_min <-  tfr_B*ppv_min + tfr_NB*(1-ppv_min)
# delta_min <-  delta*ppv_min
# n_max <-  compute_sample_size(usual_power,tfr_min,tfr_min,delta_min,alpha)
#
# ppv_max <- 0.7
# tfr_max <- tfr_B*ppv_max + tfr_NB*(1-ppv_max)
# delta_max <- delta*ppv_max
# n_min <- compute_sample_size(usual_power,tfr_max,tfr_max,delta_max,alpha)
# create data frame for plotting
require(reshape2)
power_df <- melt(power)
names(power_df) <- c("n","ppv","power")
write.csv(power_df,file="power_data_frame.csv",row.names = F)
#save(power_df,file="power_data_frame.Rdata")
#save(list=ls(),file="/Users/emt380/Documents/Spring_Semester_2019/Non-inferiority trials/shiny_app/plot_inputs.Rdata")
rm(list=ls())
power_df <- read.csv("power_data_frame.csv")
View(power_df)
rm(list=ls())
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
compute_sample_size()
runApp()
# ----------------------------------------------------------------------------------- #
# --------------- Sample plot for non-inferiority trials paper ---------------------- #
# --------------- Last updated: 02/10/19 -------------------------------------------- #
# function to compute power for equivalenc trial
power_fun <- function(N,ppv,tfr,delta,alpha){
a <- sqrt(N*(delta*ppv)^2/(2*tfr*(1-tfr))) - qnorm(1-alpha)
return(pnorm(a))
}
compute_sample_size <- function(power,tfr_E,tfr_S,delta,alpha){
(qnorm(1-alpha)+qnorm(power))^2*(tfr_E*(1-tfr_E) + tfr_S*(1-tfr_S))/(delta^2)
}
# inputs
N <- 10^seq(2,4,0.01)
ppv <- seq(0.01,1,0.001) # PPV = % of test positives who are true positives
tfr_B <- 0.1 # assumed treatment failure rate for both arms (we assume equivalence for power calculation)
tfr_NB <- 0.1 # assumed treatment failure rate for non-bacterial cases
delta <- 0.05 # equivalence margin for true treatment
delta_effective <- delta*ppv # effective equivalence margin after accounting for PPV
alpha <- 0.05 # type I error rate
# compute power
power <- outer(N,ppv,power_fun,tfr=tfr_B,delta=delta,alpha=alpha)
row.names(power) <- as.character(N)
colnames(power) <- as.character(ppv)
# compute sample size for power = 0.8 assuming PPV = 1
usual_power <- 0.8
usual_n <- compute_sample_size(usual_power,tfr_B,tfr_B,delta,alpha)
# Compute power for above sample size assuming PPV < 1
ppv_min <-  0.5
tfr_min <-  tfr_B*ppv_min + tfr_NB*(1-ppv_min)
delta_min <-  delta*ppv_min
n_max <-  compute_sample_size(usual_power,tfr_min,tfr_min,delta_min,alpha)
ppv_max <- 0.7
tfr_max <- tfr_B*ppv_max + tfr_NB*(1-ppv_max)
delta_max <- delta*ppv_max
n_min <- compute_sample_size(usual_power,tfr_max,tfr_max,delta_max,alpha)
# create data frame for plotting
require(reshape2)
power_df <- melt(power)
names(power_df) <- c("n","ppv","power")
# plot
# require(ggplot2)
# plt <- ggplot(power_df,aes(x=ppv,y=n,z=power)) + geom_contour() +
#   scale_y_continuous(trans="log10")
# plt
require(plotly)
p <- plot_ly(power_df, x = ~ppv, y = ~n, z = ~power, type = "contour", contours = list(showlabels = TRUE), width = 600, height = 500) %>%
layout(yaxis = list(type = "log"), xaxis = list(range = c(min(ppv),max(ppv)))) %>%
layout(yaxis = list(title="Sample Size Per Trial Arm"), xaxis = list(title="Positive Predictive Value (PPV)")) %>%
add_segments(x = min(power_df$ppv), xend = max(power_df$ppv), y = usual_n, yend = usual_n, line=list(color="green",dash="dashdot")) %>%
add_segments(x = ppv_min, xend = ppv_min, y = min(power_df$n), yend = n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_min, y=n_max, yend=n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = ppv_max, xend = ppv_max, y = min(power_df$n), yend = n_min, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_max, y=n_min, yend=n_min, line=list(color="orange",dash="dashdot"))
p
ppv_max <- 0.8
# ----------------------------------------------------------------------------------- #
# --------------- Sample plot for non-inferiority trials paper ---------------------- #
# --------------- Last updated: 02/10/19 -------------------------------------------- #
# function to compute power for equivalenc trial
power_fun <- function(N,ppv,tfr,delta,alpha){
a <- sqrt(N*(delta*ppv)^2/(2*tfr*(1-tfr))) - qnorm(1-alpha)
return(pnorm(a))
}
compute_sample_size <- function(power,tfr_E,tfr_S,delta,alpha){
(qnorm(1-alpha)+qnorm(power))^2*(tfr_E*(1-tfr_E) + tfr_S*(1-tfr_S))/(delta^2)
}
# inputs
N <- 10^seq(2,4,0.01)
ppv <- seq(0.01,1,0.001) # PPV = % of test positives who are true positives
tfr_B <- 0.1 # assumed treatment failure rate for both arms (we assume equivalence for power calculation)
tfr_NB <- 0.1 # assumed treatment failure rate for non-bacterial cases
delta <- 0.05 # equivalence margin for true treatment
delta_effective <- delta*ppv # effective equivalence margin after accounting for PPV
alpha <- 0.05 # type I error rate
# compute power
power <- outer(N,ppv,power_fun,tfr=tfr_B,delta=delta,alpha=alpha)
row.names(power) <- as.character(N)
colnames(power) <- as.character(ppv)
# compute sample size for power = 0.8 assuming PPV = 1
usual_power <- 0.8
usual_n <- compute_sample_size(usual_power,tfr_B,tfr_B,delta,alpha)
# Compute power for above sample size assuming PPV < 1
ppv_min <-  0.6
tfr_min <-  tfr_B*ppv_min + tfr_NB*(1-ppv_min)
delta_min <-  delta*ppv_min
n_max <-  compute_sample_size(usual_power,tfr_min,tfr_min,delta_min,alpha)
ppv_max <- 0.8
tfr_max <- tfr_B*ppv_max + tfr_NB*(1-ppv_max)
delta_max <- delta*ppv_max
n_min <- compute_sample_size(usual_power,tfr_max,tfr_max,delta_max,alpha)
# create data frame for plotting
require(reshape2)
power_df <- melt(power)
names(power_df) <- c("n","ppv","power")
# plot
# require(ggplot2)
# plt <- ggplot(power_df,aes(x=ppv,y=n,z=power)) + geom_contour() +
#   scale_y_continuous(trans="log10")
# plt
require(plotly)
p <- plot_ly(power_df, x = ~ppv, y = ~n, z = ~power, type = "contour", contours = list(showlabels = TRUE), width = 600, height = 500) %>%
layout(yaxis = list(type = "log"), xaxis = list(range = c(min(ppv),max(ppv)))) %>%
layout(yaxis = list(title="Sample Size Per Trial Arm"), xaxis = list(title="Positive Predictive Value (PPV)")) %>%
add_segments(x = min(power_df$ppv), xend = max(power_df$ppv), y = usual_n, yend = usual_n, line=list(color="green",dash="dashdot")) %>%
add_segments(x = ppv_min, xend = ppv_min, y = min(power_df$n), yend = n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_min, y=n_max, yend=n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = ppv_max, xend = ppv_max, y = min(power_df$n), yend = n_min, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_max, y=n_min, yend=n_min, line=list(color="orange",dash="dashdot"))
p
runApp()
?outer
# Compute data for contour plot
n <- 10^seq(2,4,0.01)
length(n)
ppv <- seq(0.01,1,0.001) # PPV = % of test positives who are true positives
length(ppv)
runApp()
runApp()
runApp()
# Compute data for contour plot
n <- 10^seq(2,4,length.out = 100)
ppv <- seq(0.01,1,length.out = 100) # PPV = % of test positives who are true positives
input <- list(tfr_B=0.1,delta=0.05,alpha=0.05)
inpu
input
power <- outer(n,ppv,power_fun,tfr=input$tfr_B,delta=input$delta,alpha=input$alpha)
dim(power)
row.names(power) <- as.character(N)
row.names(power) <- as.character(n)
colnames(power) <- as.character(ppv)
power_df <- melt(power)
names(power_df) <- c("n","ppv","power")
runApp()
# ----------------------------------------------------------------------------------- #
# --------------- Sample plot for non-inferiority trials paper ---------------------- #
# --------------- Last updated: 02/10/19 -------------------------------------------- #
# function to compute power for equivalenc trial
power_fun <- function(N,ppv,tfr,delta,alpha){
a <- sqrt(N*(delta*ppv)^2/(2*tfr*(1-tfr))) - qnorm(1-alpha)
return(pnorm(a))
}
compute_sample_size <- function(power,tfr_E,tfr_S,delta,alpha){
(qnorm(1-alpha)+qnorm(power))^2*(tfr_E*(1-tfr_E) + tfr_S*(1-tfr_S))/(delta^2)
}
# inputs
N <- 10^seq(2,4,0.01)
ppv <- seq(0.01,1,0.001) # PPV = % of test positives who are true positives
tfr_B <- 0.1 # assumed treatment failure rate for both arms (we assume equivalence for power calculation)
tfr_NB <- 0.1 # assumed treatment failure rate for non-bacterial cases
delta <- 0.05 # equivalence margin for true treatment
delta_effective <- delta*ppv # effective equivalence margin after accounting for PPV
alpha <- 0.05 # type I error rate
# compute power
power <- outer(N,ppv,power_fun,tfr=tfr_B,delta=delta,alpha=alpha)
row.names(power) <- as.character(N)
colnames(power) <- as.character(ppv)
# compute sample size for power = 0.8 assuming PPV = 1
usual_power <- 0.8
usual_n <- compute_sample_size(usual_power,tfr_B,tfr_B,delta,alpha)
# Compute power for above sample size assuming PPV < 1
ppv_min <-  0.6
tfr_min <-  tfr_B*ppv_min + tfr_NB*(1-ppv_min)
delta_min <-  delta*ppv_min
n_max <-  compute_sample_size(usual_power,tfr_min,tfr_min,delta_min,alpha)
ppv_max <- 0.8
tfr_max <- tfr_B*ppv_max + tfr_NB*(1-ppv_max)
delta_max <- delta*ppv_max
n_min <- compute_sample_size(usual_power,tfr_max,tfr_max,delta_max,alpha)
# create data frame for plotting
require(reshape2)
power_df <- melt(power)
names(power_df) <- c("n","ppv","power")
# plot
# require(ggplot2)
# plt <- ggplot(power_df,aes(x=ppv,y=n,z=power)) + geom_contour() +
#   scale_y_continuous(trans="log10")
# plt
require(plotly)
p <- plot_ly(power_df, x = ~ppv, y = ~n, z = ~power, type = "contour", contours = list(showlabels = TRUE), width = 600, height = 500) %>%
layout(yaxis = list(type = "log"), xaxis = list(range = c(min(ppv),max(ppv)))) %>%
layout(yaxis = list(title="Sample Size Per Trial Arm"), xaxis = list(title="Positive Predictive Value (PPV)")) %>%
add_segments(x = min(power_df$ppv), xend = max(power_df$ppv), y = usual_n, yend = usual_n, line=list(color="green",dash="dashdot")) %>%
add_segments(x = ppv_min, xend = ppv_min, y = min(power_df$n), yend = n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_min, y=n_max, yend=n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = ppv_max, xend = ppv_max, y = min(power_df$n), yend = n_min, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_max, y=n_min, yend=n_min, line=list(color="orange",dash="dashdot"))
p
# ----------------------------------------------------------------------------------- #
# --------------- Sample plot for non-inferiority trials paper ---------------------- #
# --------------- Last updated: 02/10/19 -------------------------------------------- #
# function to compute power for equivalenc trial
power_fun <- function(N,ppv,tfr,delta,alpha){
a <- sqrt(N*(delta*ppv)^2/(2*tfr*(1-tfr))) - qnorm(1-alpha)
return(pnorm(a))
}
compute_sample_size <- function(power,tfr_E,tfr_S,delta,alpha){
(qnorm(1-alpha)+qnorm(power))^2*(tfr_E*(1-tfr_E) + tfr_S*(1-tfr_S))/(delta^2)
}
# inputs
N <- 10^seq(2,4,0.01)
ppv <- seq(0.01,1,0.001) # PPV = % of test positives who are true positives
tfr_B <- 0.1 # assumed treatment failure rate for both arms (we assume equivalence for power calculation)
tfr_NB <- 0.2 # assumed treatment failure rate for non-bacterial cases
delta <- 0.05 # equivalence margin for true treatment
delta_effective <- delta*ppv # effective equivalence margin after accounting for PPV
alpha <- 0.05 # type I error rate
# compute power
power <- outer(N,ppv,power_fun,tfr=tfr_B,delta=delta,alpha=alpha)
row.names(power) <- as.character(N)
colnames(power) <- as.character(ppv)
# compute sample size for power = 0.8 assuming PPV = 1
usual_power <- 0.8
usual_n <- compute_sample_size(usual_power,tfr_B,tfr_B,delta,alpha)
# Compute power for above sample size assuming PPV < 1
ppv_min <-  0.6
tfr_min <-  tfr_B*ppv_min + tfr_NB*(1-ppv_min)
delta_min <-  delta*ppv_min
n_max <-  compute_sample_size(usual_power,tfr_min,tfr_min,delta_min,alpha)
ppv_max <- 0.8
tfr_max <- tfr_B*ppv_max + tfr_NB*(1-ppv_max)
delta_max <- delta*ppv_max
n_min <- compute_sample_size(usual_power,tfr_max,tfr_max,delta_max,alpha)
# create data frame for plotting
require(reshape2)
power_df <- melt(power)
names(power_df) <- c("n","ppv","power")
# plot
# require(ggplot2)
# plt <- ggplot(power_df,aes(x=ppv,y=n,z=power)) + geom_contour() +
#   scale_y_continuous(trans="log10")
# plt
require(plotly)
p <- plot_ly(power_df, x = ~ppv, y = ~n, z = ~power, type = "contour", contours = list(showlabels = TRUE), width = 600, height = 500) %>%
layout(yaxis = list(type = "log"), xaxis = list(range = c(min(ppv),max(ppv)))) %>%
layout(yaxis = list(title="Sample Size Per Trial Arm"), xaxis = list(title="Positive Predictive Value (PPV)")) %>%
add_segments(x = min(power_df$ppv), xend = max(power_df$ppv), y = usual_n, yend = usual_n, line=list(color="green",dash="dashdot")) %>%
add_segments(x = ppv_min, xend = ppv_min, y = min(power_df$n), yend = n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_min, y=n_max, yend=n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = ppv_max, xend = ppv_max, y = min(power_df$n), yend = n_min, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_max, y=n_min, yend=n_min, line=list(color="orange",dash="dashdot"))
p
runApp()
# ----------------------------------------------------------------------------------- #
# --------------- Sample plot for non-inferiority trials paper ---------------------- #
# --------------- Last updated: 02/10/19 -------------------------------------------- #
# function to compute power for equivalenc trial
power_fun <- function(N,ppv,tfr,delta,alpha){
a <- sqrt(N*(delta*ppv)^2/(2*tfr*(1-tfr))) - qnorm(1-alpha)
return(pnorm(a))
}
compute_sample_size <- function(power,tfr_E,tfr_S,delta,alpha){
(qnorm(1-alpha)+qnorm(power))^2*(tfr_E*(1-tfr_E) + tfr_S*(1-tfr_S))/(delta^2)
}
# inputs
N <- 10^seq(2,4,0.01)
ppv <- seq(0.01,1,0.001) # PPV = % of test positives who are true positives
tfr_B <- 0.2 # assumed treatment failure rate for both arms (we assume equivalence for power calculation)
tfr_NB <- 0.2 # assumed treatment failure rate for non-bacterial cases
delta <- 0.05 # equivalence margin for true treatment
delta_effective <- delta*ppv # effective equivalence margin after accounting for PPV
alpha <- 0.05 # type I error rate
# compute power
power <- outer(N,ppv,power_fun,tfr=tfr_B,delta=delta,alpha=alpha)
row.names(power) <- as.character(N)
colnames(power) <- as.character(ppv)
# compute sample size for power = 0.8 assuming PPV = 1
usual_power <- 0.8
usual_n <- compute_sample_size(usual_power,tfr_B,tfr_B,delta,alpha)
# Compute power for above sample size assuming PPV < 1
ppv_min <-  0.6
tfr_min <-  tfr_B*ppv_min + tfr_NB*(1-ppv_min)
delta_min <-  delta*ppv_min
n_max <-  compute_sample_size(usual_power,tfr_min,tfr_min,delta_min,alpha)
ppv_max <- 0.8
tfr_max <- tfr_B*ppv_max + tfr_NB*(1-ppv_max)
delta_max <- delta*ppv_max
n_min <- compute_sample_size(usual_power,tfr_max,tfr_max,delta_max,alpha)
# create data frame for plotting
require(reshape2)
power_df <- melt(power)
names(power_df) <- c("n","ppv","power")
# plot
# require(ggplot2)
# plt <- ggplot(power_df,aes(x=ppv,y=n,z=power)) + geom_contour() +
#   scale_y_continuous(trans="log10")
# plt
require(plotly)
p <- plot_ly(power_df, x = ~ppv, y = ~n, z = ~power, type = "contour", contours = list(showlabels = TRUE), width = 600, height = 500) %>%
layout(yaxis = list(type = "log"), xaxis = list(range = c(min(ppv),max(ppv)))) %>%
layout(yaxis = list(title="Sample Size Per Trial Arm"), xaxis = list(title="Positive Predictive Value (PPV)")) %>%
add_segments(x = min(power_df$ppv), xend = max(power_df$ppv), y = usual_n, yend = usual_n, line=list(color="green",dash="dashdot")) %>%
add_segments(x = ppv_min, xend = ppv_min, y = min(power_df$n), yend = n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_min, y=n_max, yend=n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = ppv_max, xend = ppv_max, y = min(power_df$n), yend = n_min, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_max, y=n_min, yend=n_min, line=list(color="orange",dash="dashdot"))
p
# ----------------------------------------------------------------------------------- #
# --------------- Sample plot for non-inferiority trials paper ---------------------- #
# --------------- Last updated: 02/10/19 -------------------------------------------- #
# function to compute power for equivalenc trial
power_fun <- function(N,ppv,tfr,delta,alpha){
a <- sqrt(N*(delta*ppv)^2/(2*tfr*(1-tfr))) - qnorm(1-alpha)
return(pnorm(a))
}
compute_sample_size <- function(power,tfr_E,tfr_S,delta,alpha){
(qnorm(1-alpha)+qnorm(power))^2*(tfr_E*(1-tfr_E) + tfr_S*(1-tfr_S))/(delta^2)
}
# inputs
N <- 10^seq(2,4,0.01)
ppv <- seq(0.01,1,0.001) # PPV = % of test positives who are true positives
tfr_B <- 0.5 # assumed treatment failure rate for both arms (we assume equivalence for power calculation)
tfr_NB <- 0.5 # assumed treatment failure rate for non-bacterial cases
delta <- 0.05 # equivalence margin for true treatment
delta_effective <- delta*ppv # effective equivalence margin after accounting for PPV
alpha <- 0.05 # type I error rate
# compute power
power <- outer(N,ppv,power_fun,tfr=tfr_B,delta=delta,alpha=alpha)
row.names(power) <- as.character(N)
colnames(power) <- as.character(ppv)
# compute sample size for power = 0.8 assuming PPV = 1
usual_power <- 0.8
usual_n <- compute_sample_size(usual_power,tfr_B,tfr_B,delta,alpha)
# Compute power for above sample size assuming PPV < 1
ppv_min <-  0.6
tfr_min <-  tfr_B*ppv_min + tfr_NB*(1-ppv_min)
delta_min <-  delta*ppv_min
n_max <-  compute_sample_size(usual_power,tfr_min,tfr_min,delta_min,alpha)
ppv_max <- 0.8
tfr_max <- tfr_B*ppv_max + tfr_NB*(1-ppv_max)
delta_max <- delta*ppv_max
n_min <- compute_sample_size(usual_power,tfr_max,tfr_max,delta_max,alpha)
# create data frame for plotting
require(reshape2)
power_df <- melt(power)
names(power_df) <- c("n","ppv","power")
# plot
# require(ggplot2)
# plt <- ggplot(power_df,aes(x=ppv,y=n,z=power)) + geom_contour() +
#   scale_y_continuous(trans="log10")
# plt
require(plotly)
p <- plot_ly(power_df, x = ~ppv, y = ~n, z = ~power, type = "contour", contours = list(showlabels = TRUE), width = 600, height = 500) %>%
layout(yaxis = list(type = "log"), xaxis = list(range = c(min(ppv),max(ppv)))) %>%
layout(yaxis = list(title="Sample Size Per Trial Arm"), xaxis = list(title="Positive Predictive Value (PPV)")) %>%
add_segments(x = min(power_df$ppv), xend = max(power_df$ppv), y = usual_n, yend = usual_n, line=list(color="green",dash="dashdot")) %>%
add_segments(x = ppv_min, xend = ppv_min, y = min(power_df$n), yend = n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_min, y=n_max, yend=n_max, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = ppv_max, xend = ppv_max, y = min(power_df$n), yend = n_min, line=list(color="orange",dash="dashdot")) %>%
add_segments(x = min(power_df$ppv), xend = ppv_max, y=n_min, yend=n_min, line=list(color="orange",dash="dashdot"))
p
# Compute data for contour plot
n <- 10^seq(2,4,length.out = 100)
ppv <- seq(0.01,1,length.out = 100) # PPV = % of test positives who are true positives
tfr_overall <- ppv*input$tfr_B + (1-ppv)*input$tfr_NB
tfr_overall
# Compute data for contour plot
n <- 10^seq(2,4,length.out = 100)
ppv <- seq(0.01,1,length.out = 100) # PPV = % of test positives who are true positives
input
input$tfr_NB <- 0.2
# Compute data for contour plot
n <- 10^seq(2,4,length.out = 100)
ppv <- seq(0.01,1,length.out = 100) # PPV = % of test positives who are true positives
tfr_overall <- ppv*input$tfr_B + (1-ppv)*input$tfr_NB
tfr_overall
?outer
power <- outer(n,cbind(ppv,tfr_overall),power_fun,tfr=input$tfr_B,delta=input$delta,alpha=input$alpha)
dim(power)
all.equal(power[,,1],power[,,2])
power_fun2 <- function(n,idx,ppv,tfr,delta,alpha){
# Assumes the treatment failure rate is the same in both trial arms
a <- sqrt(n*(delta*ppv[idx])^2/(2*tfr[idx]*(1-tfr[idx]))) - qnorm(1-alpha)
return(pnorm(a))
}
# Compute data for contour plot
n <- 10^seq(2,4,length.out = 100)
ppv <- seq(0.01,1,length.out = 100) # PPV = % of test positives who are true positives
tfr_overall <- ppv*input$tfr_B + (1-ppv)*input$tfr_NB
power <- outer(n,1:length(ppv),power_fun2,ppv=ppv,tfr=tfr_overall,delta=input$delta,alpha=input$alpha)
dim(power)
View(power)
runApp()
runApp()
n_max
log(n_max)
# Compute data for contour plot
log_n_max <- ceiling(max(log(n_max),4))
log_n_max
log_n_min <- floor(min(log(n_max),2))
runApp()
n_max
# Compute data for contour plot
log_n_max <- ceiling(max(log(n_max,10),4))
log_n_max
log_n_min
runApp()
input
input$delta <- 0.9
# Compute power for above sample size assuming PPV < 1
ppv_min <-  input$p_range[1]*input$sens/(input$p_range[1]*input$sens + (1-input$p_range[1])*(1-input$spec_range[1]))
tfr_min <-  input$tfr_B*ppv_min + input$tfr_NB*(1-ppv_min)
delta_min <-  input$delta*ppv_min
n_max <-  compute_sample_size(input$power,tfr_min,tfr_min,delta_min,input$alpha)
ppv_max <- input$p_range[2]*input$sens/(input$p_range[2]*input$sens + (1-input$p_range[2])*(1-input$spec_range[2]))
tfr_max <- input$tfr_B*ppv_max + input$tfr_NB*(1-ppv_max)
delta_max <- input$delta*ppv_max
n_min <- compute_sample_size(input$power,tfr_max,tfr_max,delta_max,input$alpha)
n_min
ppv_max <- input$p_range[2]*input$sens/(input$p_range[2]*input$sens + (1-input$p_range[2])*(1-input$spec_range[2]))
ppv_max
input$p_range <- c(0.1,0.4)
input$sens <- 0.7
input$sens <- 0.9
input$spec <- c(0.6,0.8)
# Compute power for above sample size assuming PPV < 1
ppv_min <-  input$p_range[1]*input$sens/(input$p_range[1]*input$sens + (1-input$p_range[1])*(1-input$spec_range[1]))
tfr_min <-  input$tfr_B*ppv_min + input$tfr_NB*(1-ppv_min)
delta_min <-  input$delta*ppv_min
n_max <-  compute_sample_size(input$power,tfr_min,tfr_min,delta_min,input$alpha)
ppv_max <- input$p_range[2]*input$sens/(input$p_range[2]*input$sens + (1-input$p_range[2])*(1-input$spec_range[2]))
tfr_max <- input$tfr_B*ppv_max + input$tfr_NB*(1-ppv_max)
delta_max <- input$delta*ppv_max
n_min <- compute_sample_size(input$power,tfr_max,tfr_max,delta_max,input$alpha)
input$spec_range <- c(0.6,0.8)
input$p_range <- c(0.1,0.4)
# Compute power for above sample size assuming PPV < 1
ppv_min <-  input$p_range[1]*input$sens/(input$p_range[1]*input$sens + (1-input$p_range[1])*(1-input$spec_range[1]))
tfr_min <-  input$tfr_B*ppv_min + input$tfr_NB*(1-ppv_min)
delta_min <-  input$delta*ppv_min
n_max <-  compute_sample_size(input$power,tfr_min,tfr_min,delta_min,input$alpha)
ppv_min
tfr_min
delta_min
input$power <- 0.8
# Compute power for above sample size assuming PPV < 1
ppv_min <-  input$p_range[1]*input$sens/(input$p_range[1]*input$sens + (1-input$p_range[1])*(1-input$spec_range[1]))
tfr_min <-  input$tfr_B*ppv_min + input$tfr_NB*(1-ppv_min)
delta_min <-  input$delta*ppv_min
n_max <-  compute_sample_size(input$power,tfr_min,tfr_min,delta_min,input$alpha)
n_max
ppv_max <- input$p_range[2]*input$sens/(input$p_range[2]*input$sens + (1-input$p_range[2])*(1-input$spec_range[2]))
tfr_max <- input$tfr_B*ppv_max + input$tfr_NB*(1-ppv_max)
delta_max <- input$delta*ppv_max
n_min <- compute_sample_size(input$power,tfr_max,tfr_max,delta_max,input$alpha)
n_min
# Compute data for contour plot
log_n_max <- ceiling(max(log(n_max,10),4))
log_n_min <- floor(min(log(n_max,10),2))
n <- 10^seq(log_n_min,log_n_max,length.out = 100)
n
runApp()
n_min
# Compute data for contour plot
log_n_max <- ceiling(max(log(n_max,10),4))
log_n_min <- floor(min(log(n_max,10),2))
n <- 10^seq(log_n_min,log_n_max,length.out = 100)
min(n)
runApp()
runApp()
?floor
floor(0.1)
runApp()
runApp()
runApp()
require(viridis)
runApp()
runApp()
runApp()
?plot_ly
?viridis_pal
runApp()
viridis_pal(begin=0,end=1,option="D")
runApp()
runApp()
runApp()
runApp()
runApp()
?colorbar
runApp()
rm(list=ls())
shiny::runApp()
